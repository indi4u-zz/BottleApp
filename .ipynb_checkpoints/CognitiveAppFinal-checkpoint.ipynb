{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# Computer Vision API\n",
    "\n",
    "# In[1]:\n",
    "from __future__ import print_function\n",
    "import bing_voice\n",
    "from bing_voice import *\n",
    "import pyaudio\n",
    "import sys\n",
    "import wave\n",
    "import os\n",
    "from bottle import route, run\n",
    "from bottle import template\n",
    "import time \n",
    "import requests\n",
    "import cv2\n",
    "import operator\n",
    "import numpy as np\n",
    "# Import library to display results\n",
    "import matplotlib.pyplot as plt\n",
    "from bottle import request\n",
    "from bottle import static_file,get\n",
    "import urllib\n",
    "#os.chdir(\"C:\\Indira\\Code\\BottleApp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_url = 'https://westus.api.cognitive.microsoft.com/vision/v1.0/analyze?'\n",
    "_key = 'ddd4c6b08a344f8494939e814aa45339'\n",
    "_maxNumRetries = 10  \n",
    "@get(\"/static/img/<filepath:re:.*\\.(jpg|png|gif|ico|svg)>\")\n",
    "def img(filepath):\n",
    "    return static_file(filepath, root=\"static/images/work/\")\n",
    "\n",
    "@get(\"/tmp/upload/<filepath:re:.*\\.(jpg|png|gif|ico|svg)>\")\n",
    "def img(filepath):\n",
    "    return static_file(filepath, root=\"tmp/upload/\")\n",
    "\n",
    "    \n",
    "@get(\"/static/css/<filepath:re:.*\\.css>\")\n",
    "def css(filepath):\n",
    "    return static_file(filepath, root=\"static/css/\")\n",
    "\n",
    "@get(\"/static/js/<filepath:re:.*\\.js>\")\n",
    "def js(filepath):\n",
    "    return static_file(filepath, root=\"static/js/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def processRequest( json, data, headers, params ):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper function to process the request to Project Oxford\n",
    "\n",
    "    Parameters:\n",
    "    json: Used when processing images from its URL. See API Documentation\n",
    "    data: Used when processing image read from disk. See API Documentation\n",
    "    headers: Used to pass the key information and the data type request\n",
    "    \"\"\"\n",
    "\n",
    "    retries = 0\n",
    "    result = None\n",
    "    while True:\n",
    "\n",
    "        response = requests.request( 'post', _url, json = json, data = data, headers = headers, params = params )\n",
    "\n",
    "        if response.status_code == 429: \n",
    "\n",
    "            print( \"Message: %s\" % ( response.json()['message'] ) )\n",
    "            \n",
    "            if retries <= _maxNumRetries: \n",
    "                time.sleep(1) \n",
    "                retries += 1\n",
    "                continue\n",
    "            else: \n",
    "                print( 'Error: failed after retrying!' )\n",
    "                break\n",
    "\n",
    "        elif response.status_code == 200 or response.status_code == 201:\n",
    "\n",
    "            if 'content-length' in response.headers and int(response.headers['content-length']) == 0: \n",
    "                result = None \n",
    "            elif 'content-type' in response.headers and isinstance(response.headers['content-type'], str): \n",
    "                if 'application/json' in response.headers['content-type'].lower(): \n",
    "                    result = response.json() if response.content else None \n",
    "                elif 'image' in response.headers['content-type'].lower(): \n",
    "                    result = response.content\n",
    "        else:\n",
    "            print( \"Error code: %d\" % ( response.status_code ) )\n",
    "            print( \"Message: %s\" % ( response.json()['message'] ) )\n",
    "            print(\"Here\")\n",
    "        break\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def renderResultOnImage( result, img ):\n",
    "   \n",
    "    \"\"\"Display the obtained results onto the input image\"\"\"\n",
    "\n",
    "    R = int(result['color']['accentColor'][:2],16)\n",
    "    G = int(result['color']['accentColor'][2:4],16)\n",
    "    B = int(result['color']['accentColor'][4:],16) ;\n",
    "    cv2.rectangle( img,(0,0), (img.shape[1], img.shape[0]), color = (R,G,B), thickness = 25 )\n",
    "\n",
    "    if 'description' in result:\n",
    "        desc = result['description']['captions'][0]['text']\n",
    "        cv2.putText( img, desc, (100,200), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, (73,25,180), 2 )\n",
    "        print(desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@route('/edit')\n",
    "def edit():\n",
    "    info = []\n",
    "    return template('simple.tpl', info)\n",
    "\n",
    "\n",
    "@route('/vision')\n",
    "def vision():\n",
    "    \n",
    "    datadic = {        \n",
    "        'category ' : \"\",\n",
    "        'description' : \"\",\n",
    "        'tags' : list()\n",
    "    }\n",
    "    return(template(\"vision.tpl\",datadic = datadic,img = \"/static/img/default.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-36-1a391d422ab2>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-1a391d422ab2>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    Exception:\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "@route('/vision/show', method = 'POST')\n",
    "def upload():\n",
    "       \n",
    "    #p = os.path.join(os.getcwd(),\"tmp/upload/\", upload.filename)\n",
    "        \n",
    "    #p = os.path.join(os.getcwd(),\"tmp/upload/\", upload.filename)\n",
    "    #upload.save(p)\n",
    "       \n",
    "    upload = request.files.get('upload')\n",
    "    name, ext = os.path.splitext(upload.filename)\n",
    "    if ext not in ('.png', '.jpg', '.jpeg'):\n",
    "        return \"File extension not allowed.\"\n",
    "\n",
    "    save_path = \"tmp/upload\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    try:\n",
    "        os.remove(save_path)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    file_path = \"{path}/{file}\".format(path=save_path, file=upload.filename)\n",
    "    print(file_path)\n",
    "    print(os.getcwd())\n",
    "    upload.save(file_path)\n",
    "    \n",
    "    with open( file_path, 'rb' ) as f:\n",
    "        data = f.read()\n",
    "   \n",
    "    # Computer Vision parameters\n",
    "    params = { 'visualFeatures' : 'Color,Categories,Faces,Description'} \n",
    "\n",
    "    headers = {}\n",
    "    headers['Ocp-Apim-Subscription-Key'] = _key\n",
    "    #headers['Content-Type'] = 'application/json' \n",
    "    headers['Content-Type'] = 'application/octet-stream'\n",
    "    json = None\n",
    "    #json = { 'url': urlImage } \n",
    "    #data = None\n",
    "    res = processRequest( json, data, headers, params)\n",
    "    print(res)\n",
    "       \n",
    "    if res is not None: \n",
    "        datadic = { 'category' : res['categories'][0]['name']  , 'description': res['description']['captions'][0]['text'] ,\n",
    "                   'tags':  res['description']['tags'][:5]}\n",
    "        print(datadic)\n",
    "        \n",
    "        return template('vision.tpl',datadic=datadic, img=\"/\"+file_path )  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bottle v0.12.13 server starting up (using WSGIRefServer())...\n",
      "Listening on http://localhost:8080/\n",
      "Hit Ctrl-C to quit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run(host='localhost', port=8080, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Text To Speech\n",
    "@route('/tts',method = \"POST\")\n",
    "def tts():      \n",
    "    # get a key from https://www.microsoft.com/cognitive-services/en-us/speech-api\n",
    "    BING_KEY = '756f8cbc3ad54b209076e4e41b51ecc2'\n",
    "    CHUNK_SIZE = 2048\n",
    "\n",
    "    text   = request.forms.get('t')\n",
    "  \n",
    "\n",
    "    bing = BingVoice(BING_KEY)\n",
    "    data = bing.synthesize(text)\n",
    "\n",
    "    pa = pyaudio.PyAudio()\n",
    "    stream = pa.open(format=pyaudio.paInt16,\n",
    "                     channels=1,\n",
    "                     rate=16000,\n",
    "                     output=True,\n",
    "                     # output_device_index=1,\n",
    "                     frames_per_buffer=CHUNK_SIZE)\n",
    "\n",
    "    stream.write(data)\n",
    "    stream.close()\n",
    "\n",
    "    if len(text) >= 3:\n",
    "        wf = wave.open(sys.argv[2], 'wb')\n",
    "        wf.setframerate(16000)\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "\n",
    "        wf.writeframes(data)\n",
    "        wf.close()\n",
    "\n",
    "\n",
    "    #return template('tts.tpl', info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@route('/tts')\n",
    "def tts():      \n",
    "    return(template('tts.tpl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@route('/spellcheck')\n",
    "def spellcheck():      \n",
    "    return(template('spellcheck.tpl',opstr = ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import  httplib\n",
    "@route('/spellcheck',method = \"POST\")\n",
    "def spellcheckpost():\n",
    "    headers = {\n",
    "    # Request headers\n",
    "    'Ocp-Apim-Subscription-Key': 'baf9b2caff1849c08a4428bf637cbbb4',\n",
    "    'Content-Type': 'application/x-www-form-urlencoded',\n",
    "    }\n",
    "    text   = request.forms.get('t')\n",
    "    s= text\n",
    "    text = \"Text=\" + text\n",
    "    params = urllib.urlencode({\n",
    "        \n",
    "        'mode': 'proof',\n",
    "        'mkt': 'en-us',\n",
    "    })\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        conn = httplib.HTTPSConnection('api.cognitive.microsoft.com')\n",
    "        conn.request(\"POST\", \"/bing/v5.0/spellcheck/?%s\" % params,text, headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read()\n",
    "        print(data)\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "           print(e)\n",
    "    print(s)\n",
    "    jsondata = json.loads(data)\n",
    "    for row in jsondata['flaggedTokens']:\n",
    "        position =  row['offset']\n",
    "        #print(row['token'])\n",
    "        replacement = row['suggestions'][0]['suggestion'] ## suggestion with the maximum score \n",
    "        length_of_replaced= len(replacement)\n",
    "        if(len(row['token']) < length_of_replaced):\n",
    "               s = s[:position] + replacement + \" \" + s[position+length_of_replaced:]\n",
    "        else:\n",
    "               s = s[:position] + replacement  + s[position+length_of_replaced:]\n",
    "    \n",
    "\n",
    "    return(template('spellcheck.tpl',opstr = s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bottle v0.12.13 server starting up (using WSGIRefServer())...\n",
      "Listening on http://localhost:8080/\n",
      "Hit Ctrl-C to quit.\n",
      "\n",
      "127.0.0.1 - - [28/Apr/2017 11:36:57] \"GET / HTTP/1.1\" 404 720\n",
      "127.0.0.1 - - [28/Apr/2017 11:37:01] \"GET /vi HTTP/1.1\" 404 724\n",
      "127.0.0.1 - - [28/Apr/2017 11:37:06] \"GET /vision HTTP/1.1\" 200 2453\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda2\\lib\\site-packages\\bottle.py\", line 862, in _handle\n",
      "    return route.call(**args)\n",
      "  File \"C:\\ProgramData\\Anaconda2\\lib\\site-packages\\bottle.py\", line 1740, in wrapper\n",
      "    rv = callback(*a, **ka)\n",
      "  File \"<ipython-input-20-d217df40a55b>\", line 19, in upload\n",
      "    upload.save(file_path)\n",
      "  File \"C:\\ProgramData\\Anaconda2\\lib\\site-packages\\bottle.py\", line 2402, in save\n",
      "    raise IOError('File exists.')\n",
      "IOError: File exists.\n",
      "127.0.0.1 - - [28/Apr/2017 11:37:14] \"POST /vision/show HTTP/1.1\" 500 1450\n"
     ]
    }
   ],
   "source": [
    "run(host='localhost', port=8080, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': u'outdoor_oceanbeach',\n",
       " 'description': u'a chair sitting in front of a beach',\n",
       " 'tags': [u'outdoor', u'water', u'beach', u'sunset', u'ocean']}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def upload():\n",
    "    upload = request.files.get('upload')\n",
    "    name, ext = os.path.splitext(upload.filename)\n",
    "    if ext not in ('.png', '.jpg', '.jpeg'):\n",
    "        return \"File extension not allowed.\"\n",
    "        \n",
    "    save_path = \"/tmp/upload\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    p = os.path.join(os.getcwd(),\"tmp/upload/\", upload.filename)\n",
    "        \n",
    "    if(os.path.exists(p)) :\n",
    "        os.remove(p)\n",
    "    \n",
    "    p = os.path.join(os.getcwd(),\"tmp/upload/\", upload.filename)\n",
    "    upload.save(p)\n",
    "       \n",
    "                         \n",
    "    with open( p, 'r' ) as f:\n",
    "        data = f.read()\n",
    "   \n",
    "    # Computer Vision parameters\n",
    "    params = { 'visualFeatures' : 'Color,Categories,Faces,Description'} \n",
    "\n",
    "    headers = {}\n",
    "    headers['Ocp-Apim-Subscription-Key'] = _key\n",
    "    #headers['Content-Type'] = 'application/json' \n",
    "    headers['Content-Type'] = 'application/octet-stream'\n",
    "    json = None\n",
    "    #json = { 'url': urlImage } \n",
    "    #data = None\n",
    "    res = processRequest( json, data, headers, params)\n",
    "    print(res)\n",
    "       \n",
    "    if res is not None: \n",
    "        datadic = { 'category' : res['categories'][0]['name']  , 'description': res['description']['captions'][0]['text'] ,\n",
    "                   'tags':  res['description']['tags'][:5]}\n",
    "        print(datadic)\n",
    "        return template('vision.tpl',datadic=datadic, img=file_path )  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict = {'category' : res['categories'][0]['name']  , 'description': res['description']['captions'][0]['text'] , 'tags':  res['description']['tags'][:5] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'categories': [{u'name': u'outdoor_oceanbeach', u'score': 0.66796875}],\n",
       " u'color': {u'accentColor': u'C28709',\n",
       "  u'dominantColorBackground': u'Brown',\n",
       "  u'dominantColorForeground': u'Brown',\n",
       "  u'dominantColors': [u'Brown', u'Yellow'],\n",
       "  u'isBWImg': False},\n",
       " u'description': {u'captions': [{u'confidence': 0.4430294665741739,\n",
       "    u'text': u'a chair sitting in front of a beach'}],\n",
       "  u'tags': [u'outdoor',\n",
       "   u'water',\n",
       "   u'beach',\n",
       "   u'sunset',\n",
       "   u'ocean',\n",
       "   u'sitting',\n",
       "   u'chair',\n",
       "   u'sun',\n",
       "   u'sand',\n",
       "   u'front',\n",
       "   u'set',\n",
       "   u'board',\n",
       "   u'man',\n",
       "   u'umbrella',\n",
       "   u'surfing',\n",
       "   u'standing']},\n",
       " u'faces': [],\n",
       " u'metadata': {u'format': u'Jpeg', u'height': 1080, u'width': 1920},\n",
       " u'requestId': u'eb75b3c1-c4c1-42d6-885a-def7812bba3d'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'a chair sitting in front of a beach'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['description']['captions'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'outdoor_oceanbeach'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['categories'][0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res['description']['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'outdoor', u'water', u'beach', u'sunset', u'ocean']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['description']['tags'][:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
